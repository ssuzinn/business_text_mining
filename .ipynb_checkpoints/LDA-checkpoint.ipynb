{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from kiwipiepy import Kiwi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('crawl_result/WINE_FREE.json','r',encoding='utf-8')as f:\n",
    "    WINE_FREE=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('crawl_result/wineQ&A_text.json','r',encoding='utf-8')as f:\n",
    "    wineQA=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('crawl_result/wine_recommend_text.json','r',encoding='utf-8')as f:\n",
    "    recommend=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "free=pd.DataFrame(WINE_FREE['data'])\n",
    "qa=pd.DataFrame(wineQA['data'])\n",
    "rec=pd.DataFrame(recommend['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'비비노 메모리얼데이 20프로 할인\\n|\\n자유게시판\\n\\n\\n\\n\\n\\n\\n\\n\\n2021.05.31. 22:24'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "free.제목[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    re_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),|]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    text = re.sub(re_pattern, 'url', text)\n",
    "    text = re.sub('[+]', ',', text)\n",
    "    text=re.sub('[^ ㄱ-ㅣ가-힣A-Za-z0-9!?.,~[]]+',' ',text)\n",
    "    text=re.sub('[\\s *]',' ',text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DF['clean_content']=DF.본문.apply(lambda x:clean_text(x))\n",
    "DF['clean_title']=DF.제목.apply(lambda x:clean_text(x))\n",
    "DF['contents']=DF.clean_title+DF.clean_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "kiwi = Kiwi(num_workers=16)\n",
    "kiwi.prepare()\n",
    "temp_title = [[each_word[0] if ('NNG' in each_word[1]) or ('NNP' in each_word[1])\n",
    "               else each_word[0] + '다' if ('VV' in each_word[1]) or ('VA' in each_word[1])\n",
    "               else None for each_word in each_doc[0][0]]\n",
    "              for each_doc in kiwi.analyze(DF['contents'], top_n=1)]\n",
    "\n",
    "target_title = [[each_word for each_word in each_doc if each_word] for each_doc in temp_title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF['token']=target_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corpus=DF.token.apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidv = TfidfVectorizer(min_df=0.01).fit(corpus)\n",
    "TFIDF=tfidv.transform(corpus)\n",
    "\n",
    "TFIDF.sum()\n",
    "text=tfidv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from wordcloud import WordCloud\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# wordclouds=WordCloud(width=800,height=800,background_color='white',colormap='Greens')\n",
    "# from collections import Counter\n",
    "# count=Counter(text)\n",
    "# fig=plt.figure(figsize=(10,10))\n",
    "# plt.imshow(wordclouds.to_array())\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 와인 등 빈도수는 높지만 불필요한 단어 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_certain_words(corpus, sparse_matrix, drop_words):\n",
    "    drop_words_index = [np.where(corpus == word)[0][0] for word in drop_words]\n",
    "    to_keep = sorted(set(range(sparse_matrix.shape[1])) - set(drop_words_index))\n",
    "    corpus = corpus[to_keep]\n",
    "    sparse_matrix = sparse_matrix[:, to_keep]\n",
    "    return corpus, sparse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "words_list, TFIDF=drop_certain_words(np.array(tfidv.get_feature_names()),TFIDF,['와인','마시다','하다','있다', \n",
    "                                                                                '댓글', '많다', '안내', '등급',\n",
    "                                                                               '답변', '기본', '소통','이렇다'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(n_components=5)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda=LatentDirichletAllocation(n_components=5)\n",
    "lda.fit(TFIDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    topics = []\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        important_words = [feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]\n",
    "\n",
    "        print(\"Topic %d:\" % topic_idx)\n",
    "        print(\" \".join(important_words))\n",
    "        topics.append(important_words)\n",
    "    return topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "보관 가격 괜찮다 되다 사다 셀러 어떻다 정도 비다 좋다\n",
      "Topic 1:\n",
      "먹다 추천 어울리다 드리다 좋다 부탁 같다 화이트 가다 레드\n",
      "Topic 2:\n",
      "행사 싸다 확인 방법 설정 알람 사람 구하다 사다 클릭\n",
      "Topic 3:\n",
      "알다 계시다 선물 받다 들다 보다 없다 정보 나오다 같다\n",
      "Topic 4:\n",
      "주목 대하다 감사 규정 체계 사항 싸다 클릭 코르크 리딩\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['보관', '가격', '괜찮다', '되다', '사다', '셀러', '어떻다', '정도', '비다', '좋다'],\n",
       " ['먹다', '추천', '어울리다', '드리다', '좋다', '부탁', '같다', '화이트', '가다', '레드'],\n",
       " ['행사', '싸다', '확인', '방법', '설정', '알람', '사람', '구하다', '사다', '클릭'],\n",
       " ['알다', '계시다', '선물', '받다', '들다', '보다', '없다', '정보', '나오다', '같다'],\n",
       " ['주목', '대하다', '감사', '규정', '체계', '사항', '싸다', '클릭', '코르크', '리딩']]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_topics(lda,words_list,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import tomotopy as tp \n",
    "\n",
    "# model = tp.LDAModel(k=10, alpha=0.1, eta=0.01, min_cf=5)\n",
    "\n",
    "# for i, line in enumerate(DF.contents.tolist()):\n",
    "#     model.add_doc(tokenize(line)) \n",
    "#     if i % 10 == 0: print('Document #{} has been loaded'.format(i))\n",
    "        \n",
    "# model.train(0) \n",
    "# print('Total docs:', len(model.docs))\n",
    "# print('Total words:', model.num_words)\n",
    "# print('Vocab size:', model.num_vocabs)\n",
    " \n",
    "\n",
    "# for i in range(200):\n",
    "#     #print('Iteration {}\\tLL per word: {}'.format(i, model.ll_per_word))\n",
    "#     model.train(1)\n",
    "    \n",
    "# for i in range(model.k):\n",
    "#     # 토픽 개수가 총 20개이니, 0~19번까지의 토픽별 상위 단어 10개를 뽑아봅시다.\n",
    "#     res = model.get_topic_words(i, top_n=10)\n",
    "#     print('Topic #{}'.format(i), end='\\t')\n",
    "#     #print(', '.join(w for w, p in res))\n",
    "#res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
